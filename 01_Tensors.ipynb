{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e2b82d8-94ca-45e6-98a4-74c986637ee4",
   "metadata": {},
   "source": [
    "<center><h1>Tensors</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0cf98d-24c7-4589-a45c-397ef0cc9c66",
   "metadata": {},
   "source": [
    "A tensor is a multi-linear algebraic object that relates sets of algebraic objects related to a vector space (like vectors and scalars). It can be represented by a multi-dimensional array of numerical components.\n",
    "\n",
    "Or you can think of them like, a tensor is a way to organize and represent data that can have multiple \"directions\" or \"indices.\" The number of these \"directions\" is called the order or rank of the tensor.\n",
    "\n",
    "Think of it like organizing information in boxes within boxes within boxes... each level of nesting adds another dimension.\n",
    "\n",
    "- Scalar: The simplest kind of data is just a single number, like your age (e.g., 30) or the temperature outside (e.g., 25 degrees Celsius). This is a 0-dimensional tensor or a scalar. It has no direction.\n",
    "\n",
    "- Vector: Now imagine you're describing the wind. You need more than just a number. You need a direction and a strength (or magnitude). For example, \"5 kilometers per hour to the East.\" This is a 1-dimensional tensor or a vector. It has one \"direction\" or axis. Think of it as an arrow in space.\n",
    "\n",
    "- Matrix: Let's say you have a table of data, like the test scores of several students in different subjects. This table has rows (students) and columns (subjects). Each entry in the table is a number, but the arrangement gives it more meaning. This entire table is a 2-dimensional tensor or a matrix. It has two \"directions\" or axes (rows and columns).\n",
    "\n",
    "- Higher-Dimensional Tensors (Beyond Matrices):Think of a multi channel image (Channel, x, y)\n",
    "\n",
    "> Ex - Imagine you have multiple of those student-subject score tables, maybe one for each grade level in a school. Now you have a collection of matrices, and you can identify each matrix by the grade level. This whole structure (all the tables organized by grade) could be thought of as a 3-dimensional tensor. It has three \"directions\" or axes (students, subjects, grades).\n",
    "\n",
    "> You can keep going! Imagine you have these grade-level score collections for multiple years. Now you have a 4-dimensional tensor (students, subjects, grades, years)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7740d4ac-c279-4fbb-b487-554e6a70f1c3",
   "metadata": {},
   "source": [
    "**The “dimension” of a tensor is the number of indices to specify\n",
    "one of its coefficients.**\n",
    "\n",
    "An element of $ \\mathbb{R}^3$ is a three-dimension vector, but a one-dimension tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "792f2102-709f-4f02-b734-d746d982e723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72741973-3b4d-44bf-b800-2fac6cba4a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(2,5)\n",
    "print(x)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03691eea-126d-4c4d-8ddf-b499f6a83d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of each tensor:  torch.Size([3]) and  torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([10., 20., 30.])\n",
    "y = torch.tensor([11., 22., 33.])\n",
    "print(\"Size of each tensor: \", x.size(), \"and \", y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45ccd58a-9816-4878-86d1-da0dab54a4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21., 42., 63.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18167f64-ba0c-483f-b795-649035498dad",
   "metadata": {},
   "source": [
    "- component-wise product and can be applied to tensors of arbitrary size, in particular of dimension greater than 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b300f376-2125-484c-a071-7fd84fd69848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([110., 440., 990.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36c96ed9-7d86-4bc3-9ca0-1553552a2081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([100., 400., 900.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73c86af3-4981-435d-9c57-f751232bc72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.tensor([[0., 0., 3.],\n",
    "                  [0., 2., 0.],\n",
    "                  [1., 0., 0.]])\n",
    "m.size()                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706f7082-cae3-41c9-97b9-c459ec7fc865",
   "metadata": {},
   "source": [
    "- Matrix - Vector multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fde79419-4d15-498f-b410-da56fed15404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([90., 40., 10.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.mv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af516af7-deea-4ddf-af21-c687c13d083d",
   "metadata": {},
   "source": [
    "- The @ operator corresponds to matrix/vector\n",
    "or matrix/matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a22a8189-4784-4a5f-b510-8205a374c280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([90., 40., 10.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m @ x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddedd94d-5b34-41a5-8d85-4bf57b1d3800",
   "metadata": {},
   "source": [
    "- Standard linear operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef252f24-f395-4ae1-be77-bc17b50b70ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0118, -1.4046,  0.0870])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.randn(3)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ebbeeb2-c6df-493f-bc7c-66d7a748c53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3422,  1.4005, -1.4339],\n",
       "        [ 0.9116,  0.0536, -3.7168],\n",
       "        [ 0.2989,  0.6960,  1.3959]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.randn(3,3)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24031f17-b5d2-416b-859c-e91ed0c16e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7269,  0.0357,  0.2001])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = torch.linalg.lstsq(m, y).solution\n",
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04f6ac4-8452-4115-a0e4-b8e67f277a5a",
   "metadata": {},
   "source": [
    "- ```torch.linalg.lstsq(m, y).solution``` calculates the least-squares solution to a system of linear equations represented by $mx=y$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4cc111d-ffa9-4c9b-b7c4-6125c8f0aaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0118, -1.4046,  0.0870])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m @ q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5fa4f78a-f095-4e1d-af91-4d38645aeb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3, 0],\n",
       "        [2, 4, 6]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([ [ 1, 3, 0 ],\n",
    "                [ 2, 4, 6 ] ])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4a09e63-d0bd-487c-906b-3c7d71fd2a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 0, 2, 4, 6])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bd1d0d-d760-4ebb-b66f-c6d20598b005",
   "metadata": {},
   "source": [
    "- Broadcasting\n",
    "\n",
    "> When the shape of the objects on which we want to perform operation are reasonable, **Broadcasting** automatically expand dimensions by replicating coefficients form one of the two objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7ad82c5-e673-4d76-acda-0f30befe4887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.9598, 2.1009, 2.0909, 1.9276]) tensor([1.0110, 1.0674, 1.0586, 0.9748])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(100, 4).normal_(2)\n",
    "print(x.mean(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "459e7830-1013-49bf-bfd4-1481bad1090c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.7684e-09, -4.7684e-09, -7.1526e-09,  4.7684e-09])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " x -= x.mean(0) \n",
    "x.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19991bee-7499-4e89-912c-4029c0dbb8ff",
   "metadata": {},
   "source": [
    "This shouldn't have worked because x.mean(0) was a tensor of size (1,4) and x is of (100,4), but it subtracted x.mean(0) from all the rows as if like it has been replicated 100 times for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "36923c80-d581-47bb-b25b-cc90da9e62ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([[1.], [2.], [3.], [4.]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c5ec1ad-5c99-41d6-9533-d7cd46d34ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5., -5.,  5., -5.,  5.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.tensor([[5., -5., 5., -5., 5.]])\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f353cb1-233b-4c75-9dc0-60fe7f0832ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6., -4.,  6., -4.,  6.],\n",
       "        [ 7., -3.,  7., -3.,  7.],\n",
       "        [ 8., -2.,  8., -2.,  8.],\n",
       "        [ 9., -1.,  9., -1.,  9.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = A + B\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c196d6-b791-43a6-b7a4-dd15e6c4c992",
   "metadata": {},
   "source": [
    "- Einstein Summation\n",
    "\n",
    "> ```torch.einsum()``` function,  is a powerful and concise way to express a wide variety of multi-dimensional tensor operations. It's based on the Einstein summation convention, a mathematical notation that simplifies expressions involving sums of products of tensor elements.\n",
    ">\n",
    "> ``torch.einsum()`` takes as argument a string describing the operation, the tensors to\n",
    "operate on, and returns a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5b320dd2-ae7b-4642-8c72-3e52dfa73d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1349, 0.0879, 0.6697, 0.6804, 0.8671],\n",
       "        [0.9849, 0.1816, 0.5192, 0.3852, 0.8469]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = torch.rand(2, 5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "19d15117-bc3b-4770-aa30-af66b0a83209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2285, 0.9549, 0.2475, 0.4728],\n",
       "        [0.0553, 0.1869, 0.3138, 0.0047],\n",
       "        [0.0716, 0.4772, 0.8463, 0.4394],\n",
       "        [0.4488, 0.9805, 0.2755, 0.6760],\n",
       "        [0.6684, 0.0474, 0.5572, 0.2332]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = torch.rand(5,4)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "795891d4-b0a7-463f-b407-36ba680e5020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9686, 1.1731, 1.2984, 1.0206],\n",
       "        [1.0112, 1.6400, 1.3183, 1.1525]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('ij,jk->ik', p, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "be6f0035-d135-4a31-aeef-694ec70819c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9686, 1.1731, 1.2984, 1.0206],\n",
       "        [1.0112, 1.6400, 1.3183, 1.1525]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p @ q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85db1936-a3bc-40d1-a6d4-54664ecd5ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
